{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "import json\n",
    "import itertools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dbs = [\"cifar-10\"] #[\"mnist\", \"cifar-10\", \"cifar-100\", \"svhn\"]\n",
    "dims = [\"d200\"] #[\"d100\", \"d200\", \"d500\"]\n",
    "dos = [\"norm\", \"reg\"]\n",
    "ons = [\"x\", \"w\"]\n",
    "stds = [\"s1o4\", \"s1o2\", \"s1o1\"]\n",
    "lyrs = [\"no\", \"l1\",  \"l2\", \"l3\", \"all\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = []\n",
    "for db, dim, do, on, std, lyr in itertools.product(dbs, dims, dos, ons, stds, lyrs):\n",
    "  label = f\"{db}_{dim}_{do}_{on}_{std}_{lyr}_1\"\n",
    "  try:\n",
    "    state = torch.load(f\"outputs/{label}/analysis.pt\")\n",
    "  except:\n",
    "    continue\n",
    "  data.append({\n",
    "    \"db\": db, \"dim\": dim, \"do\": do, \"on\": on, \"std\": std, \"lyr\": lyr,\n",
    "    **{f\"w{i}\": w.norm().item() for i, w in enumerate(state[\"ml\"][\"w\"])},\n",
    "    **{f\"b{i}\": b.norm().item() for i, b in enumerate(state[\"ml\"][\"b\"])},\n",
    "    **{f\"x{i}\": m.diagonal().sum().sqrt().item() for i, m in enumerate(state[\"ml\"][\"m2\"])},\n",
    "  })\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "mets = {\"state\": \"x\", \"weight\": \"w\", \"bias\": \"b\"}\n",
    "for i, (db, std) in enumerate(itertools.product(dbs, stds)):\n",
    "  ncols = len(dos)*len(ons)\n",
    "  nrows = len(mets)\n",
    "  _, axes = plt.subplots(\n",
    "    nrows=nrows, ncols=ncols, sharex=\"col\", sharey=\"row\",\n",
    "    figsize=(ncols*2.5, nrows*2), dpi=100, facecolor=\"w\")\n",
    "  for j, (on, do) in enumerate(itertools.product(ons, dos)):\n",
    "    sdf = df[(df[\"db\"]==db)&(df[\"dim\"]==dim)&(df[\"do\"]==do)&(df[\"on\"]==on)&(df[\"std\"]==std)]\n",
    "    if len(sdf) == 0:\n",
    "      continue\n",
    "    sdf = sdf.set_index(\"lyr\").drop(columns=[\"db\", \"dim\", \"do\", \"on\", \"std\"])\n",
    "    sdf = sdf.divide(sdf.loc[\"no\"]).drop(\"no\")\n",
    "    for k, (met, prefix) in enumerate(mets.items()):\n",
    "      cols = [col for col in sdf.columns if col.startswith(prefix)]\n",
    "      sdf[cols].plot.bar(ax=axes[k][j], legend=False, rot=0)\n",
    "      axes[k][j].set_xlabel(f\"{do} {on} {std}\")\n",
    "      axes[k][j].set_ylabel(met)\n",
    "      axes[k][j].set_ylim((0, 1.5))\n",
    "      axes[k][j].grid()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read(config):\n",
    "  data = []\n",
    "  for values in itertools.product(*config.values()):\n",
    "    label = \"_\".join(values)+\"_1\"\n",
    "    title = {k: v for k, v in zip(config.keys(), values)}\n",
    "    if title[\"detach\"] == \"ans\":\n",
    "      db, dim, do, on, detach, std, lyr = values\n",
    "      label = f\"{db}_{dim}_norm_{on}_{std}_{lyr}_1\"\n",
    "    try:\n",
    "      with open(f\"outputs/{label}/logs.json\") as f:\n",
    "          logs = json.load(f)\n",
    "      for i, log in enumerate(logs):\n",
    "          data.append({**title, \"epoch\": i+1, **log})\n",
    "    except:\n",
    "      pass\n",
    "  return pd.DataFrame(data)\n",
    "\n",
    "def plot_curve(config, x, y, g):\n",
    "  df = read(config)\n",
    "  values = list(itertools.product(*[config[k] for k in x]))\n",
    "  fields = y\n",
    "\n",
    "  ncols = len(values)\n",
    "  nrows = len(fields)\n",
    "  _, axes = plt.subplots(\n",
    "    nrows=nrows, ncols=ncols, sharex=True, sharey=\"row\",\n",
    "    figsize=(ncols*2.5, nrows*2), dpi=100, facecolor=\"w\")\n",
    "\n",
    "  for i, vs in enumerate(values):\n",
    "    label = \" \".join(vs)\n",
    "    sdf = df\n",
    "    for k, v in zip(x, vs):\n",
    "      sdf = sdf[sdf[k] == v]\n",
    "    if len(sdf) == 0:\n",
    "      continue\n",
    "    sdf = sdf.set_index(\"epoch\").groupby(g)\n",
    "    for j, field in enumerate(fields):\n",
    "      ax = axes[j][i]\n",
    "      sdf[field].plot(ax=ax, legend=False)\n",
    "      ax.set_xlabel(label)\n",
    "      ax.set_ylabel(field)\n",
    "      ax.grid()\n",
    "      if j == 0:\n",
    "        ax.legend()\n",
    "      if field == \"eval_top1\":\n",
    "        ax.set_ylim((0.45, 0.6))\n",
    "\n",
    "config = {\n",
    "  \"db\": [\"cifar-10\"],\n",
    "  \"dim\": [\"d200\"],\n",
    "  \"do\": [\"reg\"],\n",
    "  \"on\": [\"x\", \"w\"],\n",
    "  \"detach\": [\"ans\", \"no\"],\n",
    "  \"std\": [\"s1o1\"],\n",
    "  \"lyr\": [\"l1\", \"l2\", \"l3\"],\n",
    "}\n",
    "\n",
    "metsets = [\n",
    "  [\"train_loss\", \"eval_loss\", \"eval_top1\"], \n",
    "  [f\"train_model_{i}.state.l1\" for i in (4, 6, 8)] + [\"train_model.output.l1\"],\n",
    "  [f\"eval_model_{i}.weight.l1\" for i in (1, 3, 5, 7)],\n",
    "]\n",
    "for mets in metsets:\n",
    "  plot_curve(config, x=[\"do\", \"std\", \"on\", \"std\", \"lyr\"], y=mets, g=\"detach\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = []\n",
    "for db, dim, do, on, std, lyr in itertools.product(dbs, dims, dos, ons, stds, lyrs):\n",
    "  label = f\"{db}_{dim}_{do}_{on}_{std}_{lyr}_1\"\n",
    "  title = {\"db\": db, \"dim\": dim, \"do\": do, \"std\": std, \"lyr\": lyr, \"on\": on}\n",
    "  try:\n",
    "    with open(f\"outputs/{label}/logs.json\") as f:\n",
    "        logs = json.load(f)\n",
    "    for i, log in enumerate(logs):\n",
    "        data.append({**title, \"epoch\": i+1, **log})\n",
    "  except:\n",
    "    pass\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "metsets = [\n",
    "  [\"train_loss\", \"eval_loss\", \"eval_top1\"], \n",
    "  [f\"train_model_{i}.state.l1\" for i in (4, 6, 8)] + [\"train_model.output.l1\"],\n",
    "  #[f\"eval_model_{i}.weight.l1\" for i in (1, 3, 5, 7)],\n",
    "]\n",
    "for i, (db, on, mets) in enumerate(itertools.product(dbs, ons[:1], metsets)):\n",
    "  ncols = len(dos)*len(stds)\n",
    "  nrows = len(mets)\n",
    "  _, axes = plt.subplots(\n",
    "    nrows=nrows, ncols=ncols, sharex=True, sharey=\"row\",\n",
    "    figsize=(ncols*2.5, nrows*2), dpi=100, facecolor=\"w\")\n",
    "  for j, (do, std) in enumerate(itertools.product(dos, stds)):\n",
    "    sdf = df[(df[\"db\"]==db)&(df[\"dim\"]==dim)&(df[\"do\"]==do)&(df[\"std\"]==std)&(df[\"on\"]==on)]\n",
    "    if len(sdf) == 0:\n",
    "      continue\n",
    "    sdf = sdf.drop(columns=[\"db\", \"dim\", \"do\", \"on\", \"std\"])\n",
    "    sdf = sdf.set_index(\"epoch\").groupby(\"lyr\")\n",
    "    for k, met in enumerate(mets):\n",
    "      sdf[met].plot(ax=axes[k][j], legend=False)\n",
    "      axes[k][j].set_xlabel(f\"{do} {on} {std}\")\n",
    "      axes[k][j].set_ylabel(met)\n",
    "      axes[k][j].grid()\n",
    "      if met == \"eval_top1\":\n",
    "        axes[k][j].set_ylim((0.45, 0.6))\n",
    "    axes[0][j].legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot(db, dim, do, on, std, lyr, layers, flip, axes):\n",
    "  ylim, xlim = [0, 2], [-.25, .25]\n",
    "  label = f\"{db}_{dim}_{do}_{on}_{std}_{lyr}_1\"\n",
    "  try:\n",
    "    state = torch.load(f\"outputs/{label}/analysis.pt\")\n",
    "  except:\n",
    "    return\n",
    "  for j, layer in enumerate(layers):\n",
    "    w = state[\"ml\"][\"w\"][layer] if flip else state[\"ml\"][\"w\"][layer+1].T\n",
    "    x = torch.matmul(w,  w.T)\n",
    "    y = state[\"ml\"][\"m2\"][layer]\n",
    "    axes[-j-1].hist2d(\n",
    "      x.flatten().numpy(), y.flatten().numpy(), \n",
    "      range=[xlim, ylim], bins=[50, 50],\n",
    "      norm=mpl.colors.LogNorm())\n",
    "  axes[-1].set_xlabel(f\"{do} {on} {std} {lyr}\")\n",
    "\n",
    "layers = range(3)\n",
    "for db, dim, on, lyr in itertools.product(dbs, dims, ons, lyrs[1:]):\n",
    "  nrows = len(layers)\n",
    "  ncols = len(dos)*len(stds)\n",
    "  _, axes = plt.subplots(\n",
    "    nrows=nrows, ncols=ncols, sharex=True, sharey=True,\n",
    "    figsize=(ncols*2, nrows*2), dpi=100, facecolor=\"w\")\n",
    "  for i, (do, std) in enumerate(itertools.product(dos, stds)):\n",
    "    sect = [row[i] for row in axes]\n",
    "    plot(db, dim, do, on, std, lyr, layers, False, sect)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
  },
  "kernelspec": {
   "display_name": "Python 3.8.9 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
