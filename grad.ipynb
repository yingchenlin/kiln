{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "from collections import defaultdict\n",
    "\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.collections as mc\n",
    "\n",
    "from src.datasets import get_dataset\n",
    "from src.modules import get_model, get_loss_fn, get_optimizer, CaptureLayer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Engine:\n",
    "\n",
    "    def build(self, config_path):\n",
    "        with open(config_path) as f:\n",
    "            self.config = self._mod_config(json.load(f))\n",
    "        self.dataset = get_dataset(self.config[\"dataset\"], \"datasets\")\n",
    "        self.model = get_model(self.config[\"model\"], self.dataset.input_shape, self.dataset.num_classes)\n",
    "        self.loss_fn = get_loss_fn(self.config[\"fit\"][\"loss_fn\"])\n",
    "        self.mod_loss_fn = self._mod_loss_fn(self.loss_fn)\n",
    "        self.optim = get_optimizer(self.config[\"fit\"][\"optimizer\"], self.model.parameters())\n",
    "        self.num_samples = self.config[\"fit\"][\"num_samples\"]\n",
    "        self.epoch = 0\n",
    "\n",
    "    def _mod_config(self, config):\n",
    "        return config\n",
    "\n",
    "    def _mod_loss_fn(self, loss_fn):\n",
    "        return loss_fn\n",
    "\n",
    "    def load(self, checkpoint_path):\n",
    "        state = torch.load(checkpoint_path, map_location=\"cpu\")\n",
    "        self.epoch = state[\"epoch\"]\n",
    "        self.model.set_epoch(self.epoch)\n",
    "        self.model.load_state_dict(state[\"model\"])\n",
    "        self.optim.load_state_dict(state[\"optimizer\"])\n",
    "\n",
    "    def next(self):\n",
    "        self.epoch += 1\n",
    "        self.model.set_epoch(self.epoch)\n",
    "        return self.epoch\n",
    "\n",
    "    def train(self, label, device):\n",
    "        self.model.train()\n",
    "        progress = tqdm(self.dataset.train_loader, desc=label, leave=False)\n",
    "        for step, (inputs, targets) in enumerate(progress):\n",
    "            inputs = inputs.unsqueeze(0).expand(self.num_samples, *inputs.shape)\n",
    "            targets = targets.unsqueeze(0).expand(self.num_samples, *targets.shape)\n",
    "            self.optim.zero_grad()\n",
    "            outputs = self.model(inputs)\n",
    "            losses = self.mod_loss_fn(outputs, targets)\n",
    "            losses.mean().backward()\n",
    "            self.optim.step()\n",
    "            yield step + 1\n",
    "\n",
    "    def eval(self, label, device):\n",
    "        frame = defaultdict(lambda: 0)\n",
    "        self.model.train()\n",
    "        progress = tqdm(self.dataset.test_loader, desc=label, leave=False)\n",
    "        for inputs, targets in progress:\n",
    "            inputs = inputs.unsqueeze(0).expand(self.num_samples, *inputs.shape)\n",
    "            targets = targets.unsqueeze(0).expand(self.num_samples, *targets.shape)\n",
    "            self.optim.zero_grad()\n",
    "            outputs = self.model(inputs)\n",
    "            losses = self.loss_fn(outputs, targets)\n",
    "            losses.mean().backward()\n",
    "            self._add_states(frame, len(self.dataset.test_loader))\n",
    "        self._add_weights(frame)\n",
    "        return dict(frame)\n",
    "\n",
    "    def _add_weights(self, frame):\n",
    "        for i, m in enumerate(self.model):\n",
    "            if isinstance(m, nn.Linear):\n",
    "                w, n = m.weight.detach(), self.config[\"model\"][\"hidden_dim\"]\n",
    "                if m.in_features == n: frame[f\"{i}.weight.t1\"] = w.T @ w\n",
    "\n",
    "    def _add_states(self, frame, size):\n",
    "        for i, m in enumerate(self.model):\n",
    "            if isinstance(m, CaptureLayer):\n",
    "                frame[f\"{i}.state.m2\"] += self._outer_mean(m.state.detach()) / size\n",
    "                frame[f\"{i}.grad.m2\"] += self._outer_mean(m.state.grad * m.state.shape[0]) / size\n",
    "\n",
    "    def _outer_mean(self, x):\n",
    "        x = x.flatten(end_dim=-2)\n",
    "        return x.T @ x / x.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Snapshot(Engine):\n",
    "\n",
    "    def __init__(self, dir_path, label, sample, start_epoch, stop_epoch, num_steps, prefix=\"gradient\"):\n",
    "        self.start_epoch = start_epoch\n",
    "        self.stop_epoch = stop_epoch\n",
    "        self.num_steps = num_steps\n",
    "        self.output_path = f\"{dir_path}/{label}_{sample}/{prefix}-{start_epoch}-{stop_epoch}-{num_steps}.pt\"\n",
    "        self.config_path = f\"{dir_path}/{label}_{sample}/config.json\"\n",
    "        self.checkpoint_path = f\"{dir_path}/{label}_{sample}/checkpoint-{start_epoch}.pt\"\n",
    "\n",
    "    def __call__(self, device=\"cpu\"):\n",
    "        if os.path.exists(self.output_path):\n",
    "            return torch.load(self.output_path)\n",
    "        data = self._run(device)\n",
    "        torch.save(data, self.output_path)\n",
    "        return data\n",
    "\n",
    "    def _run(self, device):\n",
    "\n",
    "        self.build(self.config_path)\n",
    "        if not self.checkpoint_path.endswith(\"-0.pt\"):\n",
    "            self.load(self.checkpoint_path)\n",
    "\n",
    "        data = []\n",
    "        label = f\"{self.output_path}@{self.epoch}\"\n",
    "        data.append(self.eval(label, device))\n",
    "        while self.next() <= self.stop_epoch:\n",
    "            label = f\"{self.output_path}@{self.epoch}\"\n",
    "            for step in self.train(label, device):\n",
    "                if step % self.num_steps == 0:\n",
    "                    data.append(self.eval(label, device))\n",
    "        return data\n",
    "\n",
    "\n",
    "class SwitchSnapshot(Snapshot):\n",
    "\n",
    "    def __init__(self, dir_path, label, new_label, sample, epoch, num_epochs, num_steps):\n",
    "        super().__init__(dir_path, label, sample, epoch, num_epochs, num_steps, f\"gradient-{new_label}_{sample}\")\n",
    "        self.config_path = f\"{dir_path}/{new_label}_{sample}/config.json\"\n",
    "\n",
    "\n",
    "class DiffSnapshot(Snapshot):\n",
    "\n",
    "    def __init__(self, dir_path, label, sample, epoch, num_epochs, num_steps):\n",
    "        super().__init__(dir_path, label, sample, epoch, num_epochs, num_steps, \"gradient-diff\")\n",
    "\n",
    "    def _mod_loss_fn(self, loss_fn):\n",
    "        return  lambda x, y: loss_fn(x, y).mean(0, keepdim=True) - loss_fn(x.mean(0, keepdim=True), y[:1])\n",
    "\n",
    "\n",
    "class MeanSnapshot(Snapshot):\n",
    "\n",
    "    def __init__(self, dir_path, label, sample, epoch, num_epochs, num_steps):\n",
    "        super().__init__(dir_path, label, sample, epoch, num_epochs, num_steps, \"gradient-mean\")\n",
    "\n",
    "    def _mod_loss_fn(self, loss_fn):\n",
    "        return lambda x, y: loss_fn(x.mean(0, keepdim=True), y[:1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_epoch_length(cfg):\n",
    "    learning_rate = cfg[\"fit\"][\"optimizer\"][\"learning_rate\"]\n",
    "    batch_size = cfg[\"dataset\"][\"train\"][\"batch_size\"]\n",
    "    dataset = get_dataset(cfg[\"dataset\"], \"datasets\")\n",
    "    dataset_size = len(dataset.train_loader)\n",
    "    return learning_rate * dataset_size / batch_size\n",
    "\n",
    "def read_logs(dir_path, labels):\n",
    "    df_list = []\n",
    "    for label in labels:\n",
    "        for sample in range(10):\n",
    "            try:\n",
    "                with open(f\"{dir_path}/{label}_{sample}/config.json\") as f:\n",
    "                    cfg = json.load(f)\n",
    "                df = pd.read_json(f\"{dir_path}/{label}_{sample}/logs.json\")\n",
    "            except:\n",
    "                continue\n",
    "            df[\"label\"] = label\n",
    "            df[\"sample\"] = sample\n",
    "            df[\"epoch\"] = df.index + 1\n",
    "            df[\"length\"] = df[\"epoch\"] * get_epoch_length(cfg)\n",
    "            df_list.append(df)\n",
    "    return pd.concat(df_list)\n",
    "\n",
    "def agg_logs(df, method):\n",
    "    df = df.groupby([\"label\", \"epoch\"], sort=False).agg(method)\n",
    "    df = df.reset_index().set_index(\"epoch\").groupby(\"label\", sort=False)\n",
    "    return df\n",
    "\n",
    "def gridplot(xlabels, ylabels, sharex=True, sharey=True, xsize=2, ysize=2, dpi=100):\n",
    "    nrows, ncols = len(ylabels), len(xlabels)\n",
    "    fig, axes = plt.subplots(nrows=nrows, ncols=ncols, \n",
    "        sharex=sharex, sharey=sharey, dpi=dpi,\n",
    "        figsize=(ncols*xsize, nrows*ysize))\n",
    "    if nrows == 1: axes = [axes]\n",
    "    if ncols == 1: axes = [[ax] for ax in axes]\n",
    "    for j, xlabel in enumerate(xlabels):\n",
    "        for i, ylabel in enumerate(ylabels):\n",
    "            ax = axes[i][j]\n",
    "            if j == 0 or not sharey: ax.set_ylabel(ylabel)\n",
    "            if i == len(ylabels)-1 or not sharex: ax.set_xlabel(xlabel)\n",
    "    return fig, axes\n",
    "\n",
    "def plot_segments(ax, xs, ys, rx, ry, sat=10):\n",
    "    ax.set_xlim(*rx)\n",
    "    ax.set_ylim(*ry)\n",
    "    ax.scatter(xs[0], ys[0], s=1, c=\"gray\")\n",
    "    for x0, x1, y0, y1 in zip(xs[:-1], xs[1:], ys[:-1], ys[1:]):\n",
    "        u = (x1 - x0) / (rx[1] - rx[0])\n",
    "        v = (y1 - y0) / (ry[1] - ry[0])\n",
    "        r = (u.square() + v.square() + 1e-8).sqrt()\n",
    "        n = (r*sat).tanh() / r\n",
    "        c = yuv_color(0.5, u*n, v*n)\n",
    "        lc = mc.LineCollection(torch.stack([\n",
    "            torch.stack([x0, x1], -1), torch.stack([y0, y1], -1)\n",
    "        ], -1), colors=[tuple(v) for v in c], linewidth=0.5)\n",
    "        ax.add_collection(lc)\n",
    "\n",
    "def yuv_color(y, u, v):\n",
    "    r = y + (1.370705 * v)\n",
    "    g = y - (0.698001 * v) - (0.337633 * u)\n",
    "    b = y + (1.732446 * u)\n",
    "    r = r.clamp(0, 1)\n",
    "    g = g.clamp(0, 1)\n",
    "    b = b.clamp(0, 1)\n",
    "    return torch.stack([r, g, b], -1)\n",
    "\n",
    "def get_weight(ckpt, i, flip=False):\n",
    "    w = ckpt[\"model\"][f\"{i}.weight\"]\n",
    "    if flip:\n",
    "        w = w.T\n",
    "    return w.T @ w\n",
    "\n",
    "def get_state(ckpt, i):\n",
    "    s0 = ckpt[\"model\"][f\"{i}.test_agg.s0\"]\n",
    "    s2 = ckpt[\"model\"][f\"{i}.test_agg.s2\"]\n",
    "    return s2 / s0\n",
    "\n",
    "def outer(x):\n",
    "    return x.unsqueeze(-2) * x.unsqueeze(-1)\n",
    "\n",
    "def norm(x):\n",
    "    return x * outer(1 / x.diagonal().sqrt())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d = 100\n",
    "kind = \"off-diag\"\n",
    "if kind == \"off-diag\":\n",
    "    n = 100\n",
    "    i = torch.randint(d, size=(n,))\n",
    "    j = torch.randint(d-1, size=(n,))\n",
    "    j = j + (j >= i) # skip diagonal\n",
    "elif kind == \"diag\":\n",
    "    i = torch.arange(d)\n",
    "    j = torch.arange(d)\n",
    "elif kind == \"row\":\n",
    "    i = 0\n",
    "    j = torch.arange(d)\n",
    "idx = (i, j)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "act = \"tanh\"\n",
    "#dir_path, labels = \"outputs/lyr\", [f\"mean_{act}_l{i}\" for i in (\"\", 1, 2, 3, 123)]\n",
    "#dir_path, labels = \"outputs/onn\", [f\"mean_weight_{act}_l{i}\" for i in (\"\", 1, 2, 3, 123)]\n",
    "#dir_path, labels = \"outputs/dim\", [f\"mean_{act}_d{i}\" for i in (100, 200, 300, 400)]\n",
    "#dir_path, labels = \"outputs/std\", [f\"mean_{act}_s{v}\" for v in (0.3, 0.5, 0.7, 1.0)]\n",
    "#dir_path, labels = \"outputs/epc\", [f\"mean_{act}_b{i}\" for i in (0, 10, 20, 30, 40)]\n",
    "#dir_path, labels = \"outputs/epc\", [f\"mean_{act}_e{i}\" for i in (0, 10, 20, 30, 40)]\n",
    "dir_path, labels = \"outputs/test\", [f\"{s}_erf-t\" for s in (\"none\", \"mean\",)]\n",
    "layers = [\"layer 1\", \"layer 2\", \"layer 3\"]\n",
    "epochs = [0, 10, 20, 30, 40, 50]\n",
    "sample = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_curve_xy(mdf, xmetrics, ymetrics):\n",
    "    fig, axes = gridplot(xmetrics, [\"\"], xsize=3, ysize=3, sharex=False, sharey=False)\n",
    "    for i, (xmetric, ymetric) in enumerate(zip(xmetrics, ymetrics)):\n",
    "        ax = axes[0][i]\n",
    "        ax.set_ylabel(ymetric)\n",
    "        ax.grid(axis=\"y\")\n",
    "        for (label, x), (_, y) in zip(mdf[xmetric], mdf[ymetric]):\n",
    "            ax.plot(x, y, label=label)\n",
    "    ax.legend()\n",
    "\n",
    "def plot_curve_std(mdf, sdf, metrics):\n",
    "    fig, axes = gridplot(metrics, [\"\"], ysize=3, sharey=False)\n",
    "    for i, metric in enumerate(metrics):\n",
    "        ax = axes[0][i]\n",
    "        ax.grid(axis=\"y\")\n",
    "        for (label, m), (_, s) in zip(mdf[metric], sdf[metric]):\n",
    "            ax.plot(m, label=label)\n",
    "            ax.fill_between(m.index, m-s, m+s, alpha=0.125)\n",
    "    ax.legend()\n",
    "    \n",
    "weights = [f\"eval_${i*3+4}.weight.l2\" for i in range(3)]\n",
    "states = [f\"train_${i*3+3}.state.l2\" for i in range(3)]\n",
    "df = read_logs(dir_path, labels)\n",
    "#scale = df[\"label\"].str.slice(-3).astype(int)\n",
    "#for weight in weights: df[weight] *= scale\n",
    "mdf, sdf = agg_logs(df, \"mean\"), agg_logs(df, \"std\")\n",
    "plot_curve_std(mdf, sdf, [\"eval_recall1\", \"eval_loss\", \"train_loss\"])\n",
    "#plot_curve_xy(mdf, weights, states)\n",
    "plot_curve_std(mdf, sdf, weights)\n",
    "plot_curve_std(mdf, sdf, states)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for label in labels:\n",
    "    _, axes = gridplot([f\"{label}@{i}\" for i in epochs], layers)\n",
    "    for j, epoch in enumerate(epochs):\n",
    "        s = Snapshot(dir_path, label, sample, epoch, epoch+1, 100)()\n",
    "        for i, layer in enumerate(layers):\n",
    "            ax = axes[i][j]\n",
    "            #kx, rx = f\"{i*3+4}.weight.t1\", (-.5, .5)\n",
    "            kx, rx = f\"{i*3+3}.grad.m2\", (-2e-6, 2e-6)\n",
    "            ky, ry = f\"{i*3+3}.state.m2\", (-.5, .5)\n",
    "            xs = [t[kx][idx] for t in s]\n",
    "            ys = [t[ky][idx] for t in s]\n",
    "            plot_segments(ax, xs, ys, rx, ry)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_epochs = 5\n",
    "num_steps = 100\n",
    "n = 1000 // num_steps\n",
    "for label in labels:\n",
    "    _, axes = gridplot([f\"{label}@{epoch}\" for epoch in range(num_epochs)], layers)\n",
    "    s = Snapshot(dir_path, label, sample, 0, num_epochs, num_steps)()\n",
    "    for j, epoch in enumerate(range(num_epochs)):\n",
    "        for i, layer in enumerate(layers):\n",
    "            ax = axes[i][j]\n",
    "            #kx, rx = f\"{i*3+4}.weight.t1\", (-.5, .5)\n",
    "            kx, rx = f\"{i*3+3}.grad.m2\", (-2e-6, 2e-6)\n",
    "            ky, ry = f\"{i*3+3}.state.m2\", (-.5, .5)\n",
    "            xs = [t[kx][idx] for t in s[j*n:j*n+n]]\n",
    "            ys = [t[ky][idx] for t in s[j*n:j*n+n]]\n",
    "            plot_segments(ax, xs, ys, rx, ry)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for epoch0, epoch1 in zip(epochs[:-1], epochs[1:]):\n",
    "    _, axes = gridplot(labels, layers)\n",
    "    for j, label in enumerate(labels):\n",
    "        sample = 0\n",
    "        ckpt0 = torch.load(f\"{dir_path}/{label}_{sample}/checkpoint-{epoch0}.pt\", map_location=\"cpu\")\n",
    "        ckpt1 = torch.load(f\"{dir_path}/{label}_{sample}/checkpoint-{epoch1}.pt\", map_location=\"cpu\")\n",
    "        for i, layer in enumerate(layers):\n",
    "            ax = axes[i][j]\n",
    "            ax.set_xlim(-.5, .5)\n",
    "            ax.set_ylim(-.5, .5)\n",
    "            xs = [get_weight(c, i*4+5)[idx] for c in (ckpt0, ckpt1)]\n",
    "            ys = [get_state(c, i*4+4)[idx] for c in (ckpt0, ckpt1)]\n",
    "            plot_segments(ax, xs, ys)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.2 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
